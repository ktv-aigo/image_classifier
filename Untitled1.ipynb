{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 4706      \n",
      "=================================================================\n",
      "Total params: 4,706\n",
      "Trainable params: 4,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import Model.model as model\n",
    "\n",
    "model = model.Softmax.build((784*3,))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "Train on 750 samples, validate on 750 samples\n",
      "Epoch 1/500\n",
      "750/750 [==============================] - 0s 188us/sample - loss: 57064.2524 - acc: 0.5307 - val_loss: 67323.2673 - val_acc: 0.4987\n",
      "Epoch 2/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 64357.0858 - acc: 0.5200 - val_loss: 45849.9389 - val_acc: 0.5267\n",
      "Epoch 3/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 65007.9075 - acc: 0.5187 - val_loss: 43873.3327 - val_acc: 0.5307\n",
      "Epoch 4/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 65423.3848 - acc: 0.5067 - val_loss: 48125.5985 - val_acc: 0.5320\n",
      "Epoch 5/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 67611.6083 - acc: 0.5120 - val_loss: 86827.2603 - val_acc: 0.4960\n",
      "Epoch 6/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 77365.5990 - acc: 0.4813 - val_loss: 64773.2229 - val_acc: 0.5080\n",
      "Epoch 7/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 73401.2598 - acc: 0.4760 - val_loss: 84114.1497 - val_acc: 0.4947\n",
      "Epoch 8/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 57423.9247 - acc: 0.5507 - val_loss: 57254.8558 - val_acc: 0.5253\n",
      "Epoch 9/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 69282.9723 - acc: 0.4907 - val_loss: 69496.5278 - val_acc: 0.5120\n",
      "Epoch 10/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 59759.0657 - acc: 0.5293 - val_loss: 82379.9867 - val_acc: 0.4947\n",
      "Epoch 11/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 57022.0933 - acc: 0.5280 - val_loss: 67751.6859 - val_acc: 0.5160\n",
      "Epoch 12/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 69201.8611 - acc: 0.5040 - val_loss: 60910.8792 - val_acc: 0.5253\n",
      "Epoch 13/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 57760.3561 - acc: 0.5520 - val_loss: 65691.9681 - val_acc: 0.5200\n",
      "Epoch 14/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 57357.5316 - acc: 0.5533 - val_loss: 31780.2135 - val_acc: 0.5853\n",
      "Epoch 15/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 64806.8629 - acc: 0.5040 - val_loss: 66259.0737 - val_acc: 0.5213\n",
      "Epoch 16/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 60106.6179 - acc: 0.5440 - val_loss: 55855.6915 - val_acc: 0.5347\n",
      "Epoch 17/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 62676.5197 - acc: 0.5120 - val_loss: 93027.8093 - val_acc: 0.4947\n",
      "Epoch 18/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 63074.9474 - acc: 0.5427 - val_loss: 41985.1132 - val_acc: 0.5547\n",
      "Epoch 19/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 57208.6564 - acc: 0.5333 - val_loss: 45160.4205 - val_acc: 0.5520\n",
      "Epoch 20/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 61345.0578 - acc: 0.5413 - val_loss: 33890.3459 - val_acc: 0.5853\n",
      "Epoch 21/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 46372.2622 - acc: 0.5760 - val_loss: 84786.4971 - val_acc: 0.5000\n",
      "Epoch 22/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 76073.6633 - acc: 0.4813 - val_loss: 53212.4227 - val_acc: 0.5373\n",
      "Epoch 23/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 53935.3895 - acc: 0.5547 - val_loss: 69244.5201 - val_acc: 0.5147\n",
      "Epoch 24/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 65765.5998 - acc: 0.5213 - val_loss: 30546.2309 - val_acc: 0.6000\n",
      "Epoch 25/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 58590.7240 - acc: 0.5253 - val_loss: 68770.2024 - val_acc: 0.5173\n",
      "Epoch 26/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 63229.6942 - acc: 0.5307 - val_loss: 37293.8305 - val_acc: 0.5787\n",
      "Epoch 27/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 55372.2676 - acc: 0.5320 - val_loss: 78259.2742 - val_acc: 0.5120\n",
      "Epoch 28/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 56807.8211 - acc: 0.5560 - val_loss: 58521.9751 - val_acc: 0.5347\n",
      "Epoch 29/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 59782.7128 - acc: 0.5347 - val_loss: 50843.0800 - val_acc: 0.5520\n",
      "Epoch 30/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 60007.7560 - acc: 0.5293 - val_loss: 65296.0227 - val_acc: 0.5240\n",
      "Epoch 31/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 55011.3585 - acc: 0.5440 - val_loss: 38582.3088 - val_acc: 0.5787\n",
      "Epoch 32/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 59040.1098 - acc: 0.5360 - val_loss: 38685.0533 - val_acc: 0.5760\n",
      "Epoch 33/500\n",
      "750/750 [==============================] - 0s 55us/sample - loss: 53479.6877 - acc: 0.5613 - val_loss: 40243.4590 - val_acc: 0.5787\n",
      "Epoch 34/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 47941.7373 - acc: 0.5600 - val_loss: 64211.3989 - val_acc: 0.5307\n",
      "Epoch 35/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 55316.3100 - acc: 0.5560 - val_loss: 58788.0024 - val_acc: 0.5360\n",
      "Epoch 36/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 53416.0994 - acc: 0.5413 - val_loss: 67701.5043 - val_acc: 0.5227\n",
      "Epoch 37/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 50671.9361 - acc: 0.5667 - val_loss: 60709.0047 - val_acc: 0.5347\n",
      "Epoch 38/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 48561.7063 - acc: 0.5893 - val_loss: 44463.3087 - val_acc: 0.5720\n",
      "Epoch 39/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 54915.3987 - acc: 0.5493 - val_loss: 49594.7362 - val_acc: 0.5547\n",
      "Epoch 40/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 63830.5262 - acc: 0.5013 - val_loss: 68591.3411 - val_acc: 0.5253\n",
      "Epoch 41/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 52914.9461 - acc: 0.5560 - val_loss: 60932.2142 - val_acc: 0.5333\n",
      "Epoch 42/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 59780.8542 - acc: 0.5267 - val_loss: 70946.3499 - val_acc: 0.5213\n",
      "Epoch 43/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 45732.5099 - acc: 0.5920 - val_loss: 64823.5598 - val_acc: 0.5307\n",
      "Epoch 44/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 59580.1989 - acc: 0.5373 - val_loss: 36930.2579 - val_acc: 0.6013\n",
      "Epoch 45/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 56983.1019 - acc: 0.5333 - val_loss: 32067.4126 - val_acc: 0.6147\n",
      "Epoch 46/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 49601.4936 - acc: 0.5760 - val_loss: 49558.6192 - val_acc: 0.5587\n",
      "Epoch 47/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 52789.4503 - acc: 0.5347 - val_loss: 53421.7238 - val_acc: 0.5520\n",
      "Epoch 48/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 44086.0331 - acc: 0.6000 - val_loss: 35782.7627 - val_acc: 0.5973\n",
      "Epoch 49/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 56682.7585 - acc: 0.5400 - val_loss: 46282.7292 - val_acc: 0.5653\n",
      "Epoch 50/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 53100.9863 - acc: 0.5653 - val_loss: 35617.7220 - val_acc: 0.6040\n",
      "Epoch 51/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 41761.4552 - acc: 0.5987 - val_loss: 53025.4343 - val_acc: 0.5547\n",
      "Epoch 52/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 52573.5177 - acc: 0.5373 - val_loss: 66828.7805 - val_acc: 0.5267\n",
      "Epoch 53/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 52571.3712 - acc: 0.5560 - val_loss: 66328.9858 - val_acc: 0.5240\n",
      "Epoch 54/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 57314.4045 - acc: 0.5347 - val_loss: 49623.3082 - val_acc: 0.5573\n",
      "Epoch 55/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 46757.5771 - acc: 0.5760 - val_loss: 55775.6104 - val_acc: 0.5467\n",
      "Epoch 56/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 57190.3385 - acc: 0.5360 - val_loss: 33989.9082 - val_acc: 0.6107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 42217.8738 - acc: 0.5920 - val_loss: 57017.1156 - val_acc: 0.5480\n",
      "Epoch 58/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 47178.0416 - acc: 0.5720 - val_loss: 63938.3936 - val_acc: 0.5293\n",
      "Epoch 59/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 44666.6665 - acc: 0.6107 - val_loss: 44624.7441 - val_acc: 0.5693\n",
      "Epoch 60/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 60728.1992 - acc: 0.5387 - val_loss: 49076.2072 - val_acc: 0.5640\n",
      "Epoch 61/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 49851.9284 - acc: 0.5693 - val_loss: 59151.1247 - val_acc: 0.5360\n",
      "Epoch 62/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 49000.6372 - acc: 0.5787 - val_loss: 76305.6454 - val_acc: 0.5120\n",
      "Epoch 63/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 50512.7312 - acc: 0.5707 - val_loss: 59781.5086 - val_acc: 0.5360\n",
      "Epoch 64/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 64897.1360 - acc: 0.5133 - val_loss: 46378.1293 - val_acc: 0.5760\n",
      "Epoch 65/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 48898.3512 - acc: 0.5640 - val_loss: 48959.4033 - val_acc: 0.5680\n",
      "Epoch 66/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 46753.9046 - acc: 0.6000 - val_loss: 29871.4775 - val_acc: 0.6267\n",
      "Epoch 67/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 46736.1052 - acc: 0.5747 - val_loss: 44636.2283 - val_acc: 0.5707\n",
      "Epoch 68/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 42148.7131 - acc: 0.6200 - val_loss: 25216.2271 - val_acc: 0.6453\n",
      "Epoch 69/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 46322.0405 - acc: 0.5827 - val_loss: 42859.5322 - val_acc: 0.5787\n",
      "Epoch 70/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 42202.4211 - acc: 0.5813 - val_loss: 57186.9414 - val_acc: 0.5387\n",
      "Epoch 71/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 55014.9184 - acc: 0.5613 - val_loss: 39011.8584 - val_acc: 0.6000\n",
      "Epoch 72/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 44467.1680 - acc: 0.5800 - val_loss: 59749.3104 - val_acc: 0.5360\n",
      "Epoch 73/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 51890.3486 - acc: 0.5640 - val_loss: 48834.2883 - val_acc: 0.5600\n",
      "Epoch 74/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 56011.5182 - acc: 0.5387 - val_loss: 56737.7460 - val_acc: 0.5467\n",
      "Epoch 75/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 44573.0865 - acc: 0.5827 - val_loss: 44715.6256 - val_acc: 0.5827\n",
      "Epoch 76/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 54622.1541 - acc: 0.5373 - val_loss: 53489.2601 - val_acc: 0.5600\n",
      "Epoch 77/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 54670.9409 - acc: 0.5347 - val_loss: 51101.6366 - val_acc: 0.5707\n",
      "Epoch 78/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 47765.2503 - acc: 0.5813 - val_loss: 53271.2169 - val_acc: 0.5640\n",
      "Epoch 79/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 47753.0680 - acc: 0.5693 - val_loss: 31553.3883 - val_acc: 0.6227\n",
      "Epoch 80/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 46835.9775 - acc: 0.5760 - val_loss: 38052.1263 - val_acc: 0.6013\n",
      "Epoch 81/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 52837.9509 - acc: 0.5387 - val_loss: 51638.2082 - val_acc: 0.5560\n",
      "Epoch 82/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 57100.1809 - acc: 0.5360 - val_loss: 36518.1397 - val_acc: 0.6093\n",
      "Epoch 83/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 43025.6655 - acc: 0.5987 - val_loss: 25431.6322 - val_acc: 0.6493\n",
      "Epoch 84/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 45156.1603 - acc: 0.5893 - val_loss: 41504.4932 - val_acc: 0.5853\n",
      "Epoch 85/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 39127.7998 - acc: 0.6227 - val_loss: 36327.9676 - val_acc: 0.6080\n",
      "Epoch 86/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 42223.7496 - acc: 0.6040 - val_loss: 42727.6162 - val_acc: 0.5827\n",
      "Epoch 87/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 34286.6866 - acc: 0.6400 - val_loss: 35332.5879 - val_acc: 0.6107\n",
      "Epoch 88/500\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 31079.9307 - acc: 0.6373 - val_loss: 33901.8972 - val_acc: 0.6133\n",
      "Epoch 89/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 49969.1319 - acc: 0.5653 - val_loss: 60267.7944 - val_acc: 0.5333\n",
      "Epoch 90/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 47550.6746 - acc: 0.5667 - val_loss: 40261.2871 - val_acc: 0.5880\n",
      "Epoch 91/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 67297.5769 - acc: 0.4933 - val_loss: 73151.5616 - val_acc: 0.5093\n",
      "Epoch 92/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 44102.6424 - acc: 0.5973 - val_loss: 34371.5259 - val_acc: 0.6160\n",
      "Epoch 93/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 53556.1588 - acc: 0.5333 - val_loss: 54600.9762 - val_acc: 0.5467\n",
      "Epoch 94/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 48625.5737 - acc: 0.5787 - val_loss: 40743.1495 - val_acc: 0.5880\n",
      "Epoch 95/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 50102.1749 - acc: 0.5587 - val_loss: 38192.4426 - val_acc: 0.6013\n",
      "Epoch 96/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 37993.0200 - acc: 0.6093 - val_loss: 33007.3449 - val_acc: 0.6227\n",
      "Epoch 97/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 35360.6276 - acc: 0.6173 - val_loss: 58129.6198 - val_acc: 0.5360\n",
      "Epoch 98/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 45732.7230 - acc: 0.5893 - val_loss: 25884.8906 - val_acc: 0.6533\n",
      "Epoch 99/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 42420.7268 - acc: 0.5907 - val_loss: 53444.1674 - val_acc: 0.5493\n",
      "Epoch 100/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 48083.9644 - acc: 0.5747 - val_loss: 37270.1326 - val_acc: 0.6080\n",
      "Epoch 101/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 34288.5695 - acc: 0.6267 - val_loss: 26157.7001 - val_acc: 0.6600\n",
      "Epoch 102/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 37141.3732 - acc: 0.6013 - val_loss: 44484.6400 - val_acc: 0.5720\n",
      "Epoch 103/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 49826.1289 - acc: 0.5533 - val_loss: 56989.3887 - val_acc: 0.5453\n",
      "Epoch 104/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 46201.1315 - acc: 0.5853 - val_loss: 45156.6005 - val_acc: 0.5720\n",
      "Epoch 105/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 38077.4269 - acc: 0.6147 - val_loss: 31424.1821 - val_acc: 0.6280\n",
      "Epoch 106/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 38355.1288 - acc: 0.6067 - val_loss: 51006.7686 - val_acc: 0.5573\n",
      "Epoch 107/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 38321.4344 - acc: 0.6227 - val_loss: 40065.7545 - val_acc: 0.5987\n",
      "Epoch 108/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 48882.0971 - acc: 0.5667 - val_loss: 44511.1691 - val_acc: 0.5720\n",
      "Epoch 109/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 55946.7052 - acc: 0.5387 - val_loss: 35421.7171 - val_acc: 0.6093\n",
      "Epoch 110/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 42319.7449 - acc: 0.5840 - val_loss: 64026.7584 - val_acc: 0.5253\n",
      "Epoch 111/500\n",
      "750/750 [==============================] - 0s 56us/sample - loss: 45985.8686 - acc: 0.5813 - val_loss: 38830.4977 - val_acc: 0.6027\n",
      "Epoch 112/500\n",
      "750/750 [==============================] - 0s 66us/sample - loss: 53737.6362 - acc: 0.5360 - val_loss: 54851.0093 - val_acc: 0.5533\n",
      "Epoch 113/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 57559.7267 - acc: 0.5280 - val_loss: 46574.7103 - val_acc: 0.5760\n",
      "Epoch 114/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 52155.2722 - acc: 0.5507 - val_loss: 52494.2015 - val_acc: 0.5613\n",
      "Epoch 115/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 41332.1327 - acc: 0.6053 - val_loss: 32618.4727 - val_acc: 0.6307\n",
      "Epoch 116/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 35966.1295 - acc: 0.6067 - val_loss: 58416.5468 - val_acc: 0.5440\n",
      "Epoch 117/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 44107.1127 - acc: 0.5867 - val_loss: 50427.7494 - val_acc: 0.5587\n",
      "Epoch 118/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 44900.0403 - acc: 0.5760 - val_loss: 64164.9989 - val_acc: 0.5267\n",
      "Epoch 119/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 40897.7912 - acc: 0.6080 - val_loss: 38333.6429 - val_acc: 0.6040\n",
      "Epoch 120/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 45905.1457 - acc: 0.5680 - val_loss: 47882.2174 - val_acc: 0.5707\n",
      "Epoch 121/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 45959.2204 - acc: 0.5773 - val_loss: 45381.4768 - val_acc: 0.5760\n",
      "Epoch 122/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 42699.9940 - acc: 0.5867 - val_loss: 57560.5261 - val_acc: 0.5480\n",
      "Epoch 123/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 50588.2344 - acc: 0.5440 - val_loss: 61721.7335 - val_acc: 0.5387\n",
      "Epoch 124/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 52036.9305 - acc: 0.5560 - val_loss: 35592.4783 - val_acc: 0.6213\n",
      "Epoch 125/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 36053.0105 - acc: 0.6267 - val_loss: 41771.7224 - val_acc: 0.5920\n",
      "Epoch 126/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 42055.9741 - acc: 0.5920 - val_loss: 43597.1174 - val_acc: 0.5840\n",
      "Epoch 127/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 39122.7485 - acc: 0.6000 - val_loss: 30038.0605 - val_acc: 0.6440\n",
      "Epoch 128/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 40474.0076 - acc: 0.5813 - val_loss: 45289.9001 - val_acc: 0.5800\n",
      "Epoch 129/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 44272.9664 - acc: 0.5827 - val_loss: 31091.1446 - val_acc: 0.6360\n",
      "Epoch 130/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 41620.0918 - acc: 0.5813 - val_loss: 43180.4040 - val_acc: 0.5827\n",
      "Epoch 131/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 41434.0091 - acc: 0.6040 - val_loss: 33677.7088 - val_acc: 0.6240\n",
      "Epoch 132/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 43387.5511 - acc: 0.5693 - val_loss: 44651.8314 - val_acc: 0.5760\n",
      "Epoch 133/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 37344.8731 - acc: 0.6067 - val_loss: 48442.0963 - val_acc: 0.5707\n",
      "Epoch 134/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 50859.7451 - acc: 0.5520 - val_loss: 34738.2056 - val_acc: 0.6240\n",
      "Epoch 135/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 45165.9772 - acc: 0.5573 - val_loss: 60878.8167 - val_acc: 0.5347\n",
      "Epoch 136/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 42892.5616 - acc: 0.5933 - val_loss: 56763.7057 - val_acc: 0.5467\n",
      "Epoch 137/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 48071.8399 - acc: 0.5693 - val_loss: 26523.5841 - val_acc: 0.6667\n",
      "Epoch 138/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 50366.1532 - acc: 0.5493 - val_loss: 61020.0881 - val_acc: 0.5387\n",
      "Epoch 139/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 44533.8454 - acc: 0.5880 - val_loss: 25672.4565 - val_acc: 0.6707\n",
      "Epoch 140/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 32537.3469 - acc: 0.6347 - val_loss: 52983.9628 - val_acc: 0.5520\n",
      "Epoch 141/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 45611.7828 - acc: 0.5867 - val_loss: 31347.6635 - val_acc: 0.6360\n",
      "Epoch 142/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 33441.9141 - acc: 0.6280 - val_loss: 31138.5216 - val_acc: 0.6360\n",
      "Epoch 143/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 36863.1950 - acc: 0.6000 - val_loss: 53831.1874 - val_acc: 0.5480\n",
      "Epoch 144/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 37549.8274 - acc: 0.6173 - val_loss: 35643.5479 - val_acc: 0.6160\n",
      "Epoch 145/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 41078.4464 - acc: 0.5907 - val_loss: 39076.9021 - val_acc: 0.6040\n",
      "Epoch 146/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 37176.5981 - acc: 0.6160 - val_loss: 37793.1463 - val_acc: 0.6160\n",
      "Epoch 147/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 27885.3966 - acc: 0.6653 - val_loss: 20985.8225 - val_acc: 0.6907\n",
      "Epoch 148/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 27831.9233 - acc: 0.6667 - val_loss: 38221.6284 - val_acc: 0.5973\n",
      "Epoch 149/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 38026.8163 - acc: 0.6267 - val_loss: 22515.7927 - val_acc: 0.6867\n",
      "Epoch 150/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 45053.8536 - acc: 0.5693 - val_loss: 49470.4068 - val_acc: 0.5547\n",
      "Epoch 151/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 34259.2928 - acc: 0.6387 - val_loss: 25468.4346 - val_acc: 0.6653\n",
      "Epoch 152/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 33166.9516 - acc: 0.6227 - val_loss: 41819.4701 - val_acc: 0.5893\n",
      "Epoch 153/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 45213.2140 - acc: 0.5733 - val_loss: 50647.8926 - val_acc: 0.5533\n",
      "Epoch 154/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 41677.2275 - acc: 0.5827 - val_loss: 49830.3327 - val_acc: 0.5533\n",
      "Epoch 155/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 35584.2190 - acc: 0.6173 - val_loss: 19386.1214 - val_acc: 0.7000\n",
      "Epoch 156/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 46490.2739 - acc: 0.5813 - val_loss: 25432.5571 - val_acc: 0.6667\n",
      "Epoch 157/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 37079.7041 - acc: 0.6133 - val_loss: 35697.9316 - val_acc: 0.6120\n",
      "Epoch 158/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 36699.8104 - acc: 0.6173 - val_loss: 29734.8647 - val_acc: 0.6493\n",
      "Epoch 159/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 35299.8646 - acc: 0.6267 - val_loss: 39270.3554 - val_acc: 0.5987\n",
      "Epoch 160/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 41796.9521 - acc: 0.5853 - val_loss: 57883.2942 - val_acc: 0.5320\n",
      "Epoch 161/500\n",
      "750/750 [==============================] - 0s 70us/sample - loss: 49216.9233 - acc: 0.5640 - val_loss: 38554.4168 - val_acc: 0.6067\n",
      "Epoch 162/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 40710.8651 - acc: 0.5960 - val_loss: 49790.0206 - val_acc: 0.5560\n",
      "Epoch 163/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 40561.8569 - acc: 0.6053 - val_loss: 46153.6041 - val_acc: 0.5680\n",
      "Epoch 164/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 27487.8079 - acc: 0.6773 - val_loss: 39873.0553 - val_acc: 0.5933\n",
      "Epoch 165/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 33040.5959 - acc: 0.6373 - val_loss: 29099.0663 - val_acc: 0.6493\n",
      "Epoch 166/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 34212.5794 - acc: 0.6213 - val_loss: 40175.7188 - val_acc: 0.5853\n",
      "Epoch 167/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 35438.5049 - acc: 0.6000 - val_loss: 39941.3655 - val_acc: 0.5920\n",
      "Epoch 168/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 45479.5684 - acc: 0.5653 - val_loss: 32570.6629 - val_acc: 0.6333\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 40us/sample - loss: 39024.6463 - acc: 0.6000 - val_loss: 33622.8765 - val_acc: 0.6240\n",
      "Epoch 170/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 38450.1721 - acc: 0.6027 - val_loss: 34872.1773 - val_acc: 0.6187\n",
      "Epoch 171/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 25915.6424 - acc: 0.6747 - val_loss: 33481.0219 - val_acc: 0.6200\n",
      "Epoch 172/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 36612.7594 - acc: 0.6133 - val_loss: 41434.6615 - val_acc: 0.5827\n",
      "Epoch 173/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 42754.0345 - acc: 0.5707 - val_loss: 42295.7795 - val_acc: 0.5813\n",
      "Epoch 174/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 34755.2034 - acc: 0.6187 - val_loss: 23898.7656 - val_acc: 0.6747\n",
      "Epoch 175/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 26376.8834 - acc: 0.6693 - val_loss: 34799.8615 - val_acc: 0.6227\n",
      "Epoch 176/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 42365.6562 - acc: 0.5800 - val_loss: 21060.8876 - val_acc: 0.6973\n",
      "Epoch 177/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 38918.6962 - acc: 0.6093 - val_loss: 18480.7486 - val_acc: 0.7080\n",
      "Epoch 178/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 24690.5586 - acc: 0.6867 - val_loss: 26389.7477 - val_acc: 0.6600\n",
      "Epoch 179/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 34411.1401 - acc: 0.6080 - val_loss: 56694.1372 - val_acc: 0.5347\n",
      "Epoch 180/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 35289.7120 - acc: 0.6467 - val_loss: 16130.4592 - val_acc: 0.7200\n",
      "Epoch 181/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 30640.6240 - acc: 0.6347 - val_loss: 38698.0965 - val_acc: 0.6000\n",
      "Epoch 182/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 41760.3344 - acc: 0.5653 - val_loss: 46949.5922 - val_acc: 0.5640\n",
      "Epoch 183/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 43293.7588 - acc: 0.5813 - val_loss: 33625.2019 - val_acc: 0.6267\n",
      "Epoch 184/500\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 32870.6418 - acc: 0.6373 - val_loss: 45758.2791 - val_acc: 0.5720\n",
      "Epoch 185/500\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 41533.6431 - acc: 0.5933 - val_loss: 36199.2432 - val_acc: 0.6107\n",
      "Epoch 186/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 39677.4953 - acc: 0.5853 - val_loss: 65054.0383 - val_acc: 0.5200\n",
      "Epoch 187/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 47968.0176 - acc: 0.5693 - val_loss: 37182.1853 - val_acc: 0.6120\n",
      "Epoch 188/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 24275.7719 - acc: 0.6920 - val_loss: 46036.0592 - val_acc: 0.5693\n",
      "Epoch 189/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 31114.5959 - acc: 0.6573 - val_loss: 9059.0505 - val_acc: 0.7907\n",
      "Epoch 190/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 21485.6307 - acc: 0.7080 - val_loss: 35312.8432 - val_acc: 0.6067\n",
      "Epoch 191/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 33720.3132 - acc: 0.6333 - val_loss: 27003.0589 - val_acc: 0.6493\n",
      "Epoch 192/500\n",
      "750/750 [==============================] - 0s 57us/sample - loss: 37867.3019 - acc: 0.5960 - val_loss: 33252.9885 - val_acc: 0.6160\n",
      "Epoch 193/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 38692.5849 - acc: 0.5893 - val_loss: 62416.3301 - val_acc: 0.5360\n",
      "Epoch 194/500\n",
      "750/750 [==============================] - 0s 55us/sample - loss: 34383.3686 - acc: 0.6360 - val_loss: 39890.5992 - val_acc: 0.5880\n",
      "Epoch 195/500\n",
      "750/750 [==============================] - 0s 57us/sample - loss: 41219.4524 - acc: 0.5933 - val_loss: 22143.5078 - val_acc: 0.6893\n",
      "Epoch 196/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 43349.4788 - acc: 0.5773 - val_loss: 39022.2665 - val_acc: 0.5920\n",
      "Epoch 197/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 45658.8703 - acc: 0.5573 - val_loss: 36974.5217 - val_acc: 0.6040\n",
      "Epoch 198/500\n",
      "750/750 [==============================] - 0s 60us/sample - loss: 35804.3669 - acc: 0.6387 - val_loss: 28858.7823 - val_acc: 0.6467\n",
      "Epoch 199/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 36826.0151 - acc: 0.6080 - val_loss: 28959.0148 - val_acc: 0.6440\n",
      "Epoch 200/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 47007.7771 - acc: 0.5547 - val_loss: 39949.1896 - val_acc: 0.5867\n",
      "Epoch 201/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 34102.2895 - acc: 0.6227 - val_loss: 40286.1258 - val_acc: 0.5893\n",
      "Epoch 202/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 45463.9101 - acc: 0.5720 - val_loss: 28417.9127 - val_acc: 0.6480\n",
      "Epoch 203/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 29188.5956 - acc: 0.6453 - val_loss: 23928.3488 - val_acc: 0.6733\n",
      "Epoch 204/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 28361.2869 - acc: 0.6680 - val_loss: 21147.0513 - val_acc: 0.6920\n",
      "Epoch 205/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 32142.4140 - acc: 0.6227 - val_loss: 45311.0887 - val_acc: 0.5707\n",
      "Epoch 206/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 27676.7875 - acc: 0.6613 - val_loss: 36642.7607 - val_acc: 0.5987\n",
      "Epoch 207/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 35770.8007 - acc: 0.6160 - val_loss: 27572.3254 - val_acc: 0.6547\n",
      "Epoch 208/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 19806.8222 - acc: 0.7173 - val_loss: 10878.4787 - val_acc: 0.7813\n",
      "Epoch 209/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 8555.3515 - acc: 0.8027 - val_loss: 10976.8224 - val_acc: 0.7573\n",
      "Epoch 210/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 19219.9526 - acc: 0.7160 - val_loss: 30025.7203 - val_acc: 0.6307\n",
      "Epoch 211/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 40815.0833 - acc: 0.5867 - val_loss: 30634.2383 - val_acc: 0.6293\n",
      "Epoch 212/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 27992.2974 - acc: 0.6493 - val_loss: 27893.1801 - val_acc: 0.6520\n",
      "Epoch 213/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 33780.9140 - acc: 0.6227 - val_loss: 35840.9060 - val_acc: 0.6000\n",
      "Epoch 214/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 38797.9852 - acc: 0.5800 - val_loss: 46342.2458 - val_acc: 0.5680\n",
      "Epoch 215/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 34628.8900 - acc: 0.6267 - val_loss: 27249.9918 - val_acc: 0.6547\n",
      "Epoch 216/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 33865.7488 - acc: 0.6240 - val_loss: 40127.2529 - val_acc: 0.5840\n",
      "Epoch 217/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 34339.3361 - acc: 0.6213 - val_loss: 34912.3374 - val_acc: 0.6107\n",
      "Epoch 218/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 32489.0044 - acc: 0.6360 - val_loss: 15812.8362 - val_acc: 0.7280\n",
      "Epoch 219/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 28536.4700 - acc: 0.6507 - val_loss: 26270.8660 - val_acc: 0.6587\n",
      "Epoch 220/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 23893.1811 - acc: 0.6653 - val_loss: 58515.5833 - val_acc: 0.5253\n",
      "Epoch 221/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 35458.4908 - acc: 0.6240 - val_loss: 42002.5316 - val_acc: 0.5813\n",
      "Epoch 222/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 45007.9420 - acc: 0.5627 - val_loss: 37512.0108 - val_acc: 0.6013\n",
      "Epoch 223/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 38874.9936 - acc: 0.5947 - val_loss: 59837.3466 - val_acc: 0.5280\n",
      "Epoch 224/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 34640.0724 - acc: 0.6293 - val_loss: 34095.8522 - val_acc: 0.6147\n",
      "Epoch 225/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 37888.7750 - acc: 0.6133 - val_loss: 34915.7423 - val_acc: 0.6133\n",
      "Epoch 226/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 44677.3336 - acc: 0.5480 - val_loss: 40884.1711 - val_acc: 0.5840\n",
      "Epoch 227/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 36620.4791 - acc: 0.6120 - val_loss: 44498.8033 - val_acc: 0.5680\n",
      "Epoch 228/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 29084.4469 - acc: 0.6573 - val_loss: 25040.8562 - val_acc: 0.6707\n",
      "Epoch 229/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 29531.2475 - acc: 0.6253 - val_loss: 20797.4417 - val_acc: 0.6973\n",
      "Epoch 230/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 39385.7170 - acc: 0.5880 - val_loss: 29288.8254 - val_acc: 0.6467\n",
      "Epoch 231/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 16131.3371 - acc: 0.7533 - val_loss: 9962.9162 - val_acc: 0.7880\n",
      "Epoch 232/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 12369.0929 - acc: 0.7573 - val_loss: 37839.1717 - val_acc: 0.5933\n",
      "Epoch 233/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 42218.4717 - acc: 0.5867 - val_loss: 22420.1860 - val_acc: 0.6840\n",
      "Epoch 234/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 31379.0648 - acc: 0.6213 - val_loss: 46778.0347 - val_acc: 0.5640\n",
      "Epoch 235/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 50499.7237 - acc: 0.5413 - val_loss: 38038.1016 - val_acc: 0.5987\n",
      "Epoch 236/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 37908.8267 - acc: 0.5907 - val_loss: 38791.8052 - val_acc: 0.5920\n",
      "Epoch 237/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 30992.7738 - acc: 0.6547 - val_loss: 37453.7255 - val_acc: 0.6013\n",
      "Epoch 238/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 29951.3364 - acc: 0.6600 - val_loss: 19146.2793 - val_acc: 0.7067\n",
      "Epoch 239/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 9516.2441 - acc: 0.8053 - val_loss: 8266.0119 - val_acc: 0.8040\n",
      "Epoch 240/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 19578.9161 - acc: 0.7107 - val_loss: 37324.0633 - val_acc: 0.5947\n",
      "Epoch 241/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 38572.2101 - acc: 0.5893 - val_loss: 30619.7209 - val_acc: 0.6333\n",
      "Epoch 242/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 29719.9989 - acc: 0.6320 - val_loss: 32717.5446 - val_acc: 0.6227\n",
      "Epoch 243/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 33822.3254 - acc: 0.6253 - val_loss: 26532.3610 - val_acc: 0.6640\n",
      "Epoch 244/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 41467.9427 - acc: 0.5933 - val_loss: 17669.4116 - val_acc: 0.7173\n",
      "Epoch 245/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 38743.7918 - acc: 0.6000 - val_loss: 35052.3752 - val_acc: 0.6013\n",
      "Epoch 246/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 21183.1803 - acc: 0.7013 - val_loss: 31509.6587 - val_acc: 0.6293\n",
      "Epoch 247/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 36949.7909 - acc: 0.5867 - val_loss: 61845.0478 - val_acc: 0.5213\n",
      "Epoch 248/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 34246.3128 - acc: 0.6213 - val_loss: 33235.0577 - val_acc: 0.6187\n",
      "Epoch 249/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 34829.2787 - acc: 0.6133 - val_loss: 31096.8410 - val_acc: 0.6320\n",
      "Epoch 250/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 32693.8434 - acc: 0.6480 - val_loss: 10674.1347 - val_acc: 0.7733\n",
      "Epoch 251/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 20065.6655 - acc: 0.6960 - val_loss: 19161.7205 - val_acc: 0.7040\n",
      "Epoch 252/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 17171.8119 - acc: 0.7307 - val_loss: 18781.0880 - val_acc: 0.7080\n",
      "Epoch 253/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 23969.8104 - acc: 0.6733 - val_loss: 52051.5596 - val_acc: 0.5480\n",
      "Epoch 254/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 35737.5730 - acc: 0.6093 - val_loss: 45255.6848 - val_acc: 0.5680\n",
      "Epoch 255/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 43421.9406 - acc: 0.5680 - val_loss: 34943.2425 - val_acc: 0.6080\n",
      "Epoch 256/500\n",
      "750/750 [==============================] - 0s 36us/sample - loss: 42178.5772 - acc: 0.5760 - val_loss: 28853.7246 - val_acc: 0.6387\n",
      "Epoch 257/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 39501.7793 - acc: 0.5840 - val_loss: 74250.6677 - val_acc: 0.5093\n",
      "Epoch 258/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 39945.2232 - acc: 0.6133 - val_loss: 23238.9466 - val_acc: 0.6813\n",
      "Epoch 259/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 18613.3235 - acc: 0.7147 - val_loss: 27188.7925 - val_acc: 0.6613\n",
      "Epoch 260/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 24145.2666 - acc: 0.6733 - val_loss: 54828.0601 - val_acc: 0.5440\n",
      "Epoch 261/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 35804.1666 - acc: 0.6080 - val_loss: 23503.7281 - val_acc: 0.6853\n",
      "Epoch 262/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 28295.7401 - acc: 0.6587 - val_loss: 25492.8552 - val_acc: 0.6680\n",
      "Epoch 263/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 21284.2784 - acc: 0.6973 - val_loss: 49394.0227 - val_acc: 0.5520\n",
      "Epoch 264/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 25381.3427 - acc: 0.6733 - val_loss: 49441.8555 - val_acc: 0.5560\n",
      "Epoch 265/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 39040.4853 - acc: 0.6000 - val_loss: 32351.3682 - val_acc: 0.6200\n",
      "Epoch 266/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 32766.8933 - acc: 0.6253 - val_loss: 27321.7713 - val_acc: 0.6560\n",
      "Epoch 267/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 34087.1364 - acc: 0.6227 - val_loss: 31426.7353 - val_acc: 0.6187\n",
      "Epoch 268/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 26070.7967 - acc: 0.7080 - val_loss: 14321.8249 - val_acc: 0.7360\n",
      "Epoch 269/500\n",
      "750/750 [==============================] - 0s 53us/sample - loss: 24681.3639 - acc: 0.6693 - val_loss: 23725.5094 - val_acc: 0.6733\n",
      "Epoch 270/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 31748.3924 - acc: 0.6107 - val_loss: 43321.0373 - val_acc: 0.5707\n",
      "Epoch 271/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 37200.3785 - acc: 0.6013 - val_loss: 15720.6317 - val_acc: 0.7267\n",
      "Epoch 272/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 23786.9600 - acc: 0.6773 - val_loss: 27552.0734 - val_acc: 0.6467\n",
      "Epoch 273/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 31359.5773 - acc: 0.6333 - val_loss: 31674.9831 - val_acc: 0.6147\n",
      "Epoch 274/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 27703.9465 - acc: 0.6493 - val_loss: 42570.0905 - val_acc: 0.5707\n",
      "Epoch 275/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 38139.0548 - acc: 0.6040 - val_loss: 8401.8768 - val_acc: 0.8173\n",
      "Epoch 276/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 7087.3592 - acc: 0.8293 - val_loss: 6775.8561 - val_acc: 0.8280\n",
      "Epoch 277/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 6670.6751 - acc: 0.8333 - val_loss: 6912.5452 - val_acc: 0.8307\n",
      "Epoch 278/500\n",
      "750/750 [==============================] - 0s 56us/sample - loss: 13607.7336 - acc: 0.7693 - val_loss: 36617.0571 - val_acc: 0.5853\n",
      "Epoch 279/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 28918.1361 - acc: 0.6267 - val_loss: 29394.4703 - val_acc: 0.6360\n",
      "Epoch 280/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 16091.6625 - acc: 0.7427 - val_loss: 14637.1995 - val_acc: 0.7413\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 47us/sample - loss: 13681.2374 - acc: 0.7507 - val_loss: 38183.9941 - val_acc: 0.5787\n",
      "Epoch 282/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 40471.9692 - acc: 0.5680 - val_loss: 52597.9355 - val_acc: 0.5413\n",
      "Epoch 283/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 32377.9330 - acc: 0.6227 - val_loss: 20924.9865 - val_acc: 0.6893\n",
      "Epoch 284/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 37746.2501 - acc: 0.5987 - val_loss: 16435.5081 - val_acc: 0.7280\n",
      "Epoch 285/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 23017.1891 - acc: 0.6920 - val_loss: 26607.2519 - val_acc: 0.6507\n",
      "Epoch 286/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 37379.6213 - acc: 0.5960 - val_loss: 78209.1948 - val_acc: 0.5240\n",
      "Epoch 287/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 27266.2451 - acc: 0.6907 - val_loss: 33963.3523 - val_acc: 0.5973\n",
      "Epoch 288/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 38421.4849 - acc: 0.5907 - val_loss: 25362.5439 - val_acc: 0.6587\n",
      "Epoch 289/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 26990.1111 - acc: 0.6640 - val_loss: 25228.4563 - val_acc: 0.6560\n",
      "Epoch 290/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 27051.3831 - acc: 0.6467 - val_loss: 46592.6199 - val_acc: 0.5493\n",
      "Epoch 291/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 30806.3108 - acc: 0.6213 - val_loss: 43863.1693 - val_acc: 0.5573\n",
      "Epoch 292/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 32437.2046 - acc: 0.6213 - val_loss: 40122.0481 - val_acc: 0.5773\n",
      "Epoch 293/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 38189.8699 - acc: 0.5827 - val_loss: 30543.6654 - val_acc: 0.6267\n",
      "Epoch 294/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 29256.8889 - acc: 0.6320 - val_loss: 27796.5893 - val_acc: 0.6440\n",
      "Epoch 295/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 28879.1787 - acc: 0.6400 - val_loss: 12504.4090 - val_acc: 0.7693\n",
      "Epoch 296/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 17425.2393 - acc: 0.7107 - val_loss: 33408.5923 - val_acc: 0.6027\n",
      "Epoch 297/500\n",
      "750/750 [==============================] - 0s 62us/sample - loss: 23808.7909 - acc: 0.6813 - val_loss: 35752.1314 - val_acc: 0.5893\n",
      "Epoch 298/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 25096.8611 - acc: 0.6720 - val_loss: 15265.5449 - val_acc: 0.7480\n",
      "Epoch 299/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 10808.7201 - acc: 0.7787 - val_loss: 18910.4909 - val_acc: 0.7133\n",
      "Epoch 300/500\n",
      "750/750 [==============================] - 0s 55us/sample - loss: 36935.3477 - acc: 0.5920 - val_loss: 36786.3444 - val_acc: 0.5867\n",
      "Epoch 301/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 32729.8924 - acc: 0.6107 - val_loss: 30165.8962 - val_acc: 0.6280\n",
      "Epoch 302/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 31027.4851 - acc: 0.6307 - val_loss: 47481.7448 - val_acc: 0.5507\n",
      "Epoch 303/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 31996.4746 - acc: 0.6360 - val_loss: 15367.1589 - val_acc: 0.7413\n",
      "Epoch 304/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 20922.2685 - acc: 0.6973 - val_loss: 52774.1163 - val_acc: 0.5427\n",
      "Epoch 305/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 40121.3807 - acc: 0.5840 - val_loss: 28169.6183 - val_acc: 0.6453\n",
      "Epoch 306/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 32378.0604 - acc: 0.6253 - val_loss: 27587.2154 - val_acc: 0.6507\n",
      "Epoch 307/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 22265.1385 - acc: 0.6853 - val_loss: 37132.4584 - val_acc: 0.5907\n",
      "Epoch 308/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 22661.6072 - acc: 0.6773 - val_loss: 37066.1222 - val_acc: 0.5853\n",
      "Epoch 309/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 27135.5802 - acc: 0.6347 - val_loss: 22714.9274 - val_acc: 0.6827\n",
      "Epoch 310/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 15778.6896 - acc: 0.7427 - val_loss: 7787.7409 - val_acc: 0.8240\n",
      "Epoch 311/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 7242.8835 - acc: 0.8120 - val_loss: 24299.1370 - val_acc: 0.6747\n",
      "Epoch 312/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 30026.9389 - acc: 0.6547 - val_loss: 21151.0241 - val_acc: 0.6987\n",
      "Epoch 313/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 25420.3585 - acc: 0.6573 - val_loss: 25648.5621 - val_acc: 0.6600\n",
      "Epoch 314/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 21775.8601 - acc: 0.6973 - val_loss: 44891.2721 - val_acc: 0.5573\n",
      "Epoch 315/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 15043.1795 - acc: 0.7600 - val_loss: 6076.6481 - val_acc: 0.8467\n",
      "Epoch 316/500\n",
      "750/750 [==============================] - 0s 59us/sample - loss: 9463.3516 - acc: 0.7920 - val_loss: 20634.7075 - val_acc: 0.6787\n",
      "Epoch 317/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 35611.6005 - acc: 0.5987 - val_loss: 11827.5360 - val_acc: 0.7667\n",
      "Epoch 318/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 11314.2630 - acc: 0.7827 - val_loss: 13289.7125 - val_acc: 0.7467\n",
      "Epoch 319/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 13724.4513 - acc: 0.7573 - val_loss: 27765.1986 - val_acc: 0.6293\n",
      "Epoch 320/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 36258.6384 - acc: 0.5893 - val_loss: 25459.7215 - val_acc: 0.6480\n",
      "Epoch 321/500\n",
      "750/750 [==============================] - 0s 55us/sample - loss: 27716.4074 - acc: 0.6507 - val_loss: 32125.6914 - val_acc: 0.6067\n",
      "Epoch 322/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 23533.2198 - acc: 0.6973 - val_loss: 20484.2892 - val_acc: 0.6907\n",
      "Epoch 323/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 18215.2786 - acc: 0.7067 - val_loss: 32230.2181 - val_acc: 0.6027\n",
      "Epoch 324/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 20116.0494 - acc: 0.7053 - val_loss: 14565.6607 - val_acc: 0.7413\n",
      "Epoch 325/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 18616.1916 - acc: 0.7147 - val_loss: 43443.5366 - val_acc: 0.5600\n",
      "Epoch 326/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 32108.6154 - acc: 0.6187 - val_loss: 27033.8985 - val_acc: 0.6347\n",
      "Epoch 327/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 17983.7442 - acc: 0.7293 - val_loss: 16722.1206 - val_acc: 0.7213\n",
      "Epoch 328/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 7964.0313 - acc: 0.8200 - val_loss: 6855.2282 - val_acc: 0.8253\n",
      "Epoch 329/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 16483.4747 - acc: 0.7280 - val_loss: 31614.4296 - val_acc: 0.6027\n",
      "Epoch 330/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 26730.7030 - acc: 0.6413 - val_loss: 27720.2830 - val_acc: 0.6307\n",
      "Epoch 331/500\n",
      "750/750 [==============================] - 0s 58us/sample - loss: 16850.5935 - acc: 0.7320 - val_loss: 37908.3377 - val_acc: 0.5813\n",
      "Epoch 332/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 25898.1703 - acc: 0.6547 - val_loss: 28464.6189 - val_acc: 0.6267\n",
      "Epoch 333/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 34381.8364 - acc: 0.5947 - val_loss: 22350.8308 - val_acc: 0.6680\n",
      "Epoch 334/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 37052.7329 - acc: 0.5773 - val_loss: 40024.4310 - val_acc: 0.5720\n",
      "Epoch 335/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 22368.7343 - acc: 0.7200 - val_loss: 7189.4874 - val_acc: 0.8187\n",
      "Epoch 336/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 12159.3110 - acc: 0.7773 - val_loss: 19579.2738 - val_acc: 0.6920\n",
      "Epoch 337/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 32394.3169 - acc: 0.6080 - val_loss: 28755.9605 - val_acc: 0.6280\n",
      "Epoch 338/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 18854.0395 - acc: 0.7213 - val_loss: 13734.5573 - val_acc: 0.7480\n",
      "Epoch 339/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 14521.9849 - acc: 0.7333 - val_loss: 30276.9280 - val_acc: 0.6160\n",
      "Epoch 340/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 26705.9736 - acc: 0.6507 - val_loss: 24727.5471 - val_acc: 0.6560\n",
      "Epoch 341/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 25462.3624 - acc: 0.6640 - val_loss: 18376.4352 - val_acc: 0.7067\n",
      "Epoch 342/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 12443.1122 - acc: 0.7800 - val_loss: 8806.8974 - val_acc: 0.7920\n",
      "Epoch 343/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 22604.0031 - acc: 0.6840 - val_loss: 41239.3626 - val_acc: 0.5667\n",
      "Epoch 344/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 32672.9199 - acc: 0.6253 - val_loss: 23054.0950 - val_acc: 0.6667\n",
      "Epoch 345/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 27723.1154 - acc: 0.6520 - val_loss: 16860.1217 - val_acc: 0.7213\n",
      "Epoch 346/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 28625.7069 - acc: 0.6320 - val_loss: 28745.8962 - val_acc: 0.6267\n",
      "Epoch 347/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 30793.1946 - acc: 0.6240 - val_loss: 22095.1864 - val_acc: 0.6733\n",
      "Epoch 348/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 25390.3446 - acc: 0.6560 - val_loss: 20664.9022 - val_acc: 0.6840\n",
      "Epoch 349/500\n",
      "750/750 [==============================] - 0s 55us/sample - loss: 33554.2748 - acc: 0.6027 - val_loss: 19497.0195 - val_acc: 0.6987\n",
      "Epoch 350/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 18018.7645 - acc: 0.7040 - val_loss: 16131.6798 - val_acc: 0.7307\n",
      "Epoch 351/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 32844.3791 - acc: 0.6240 - val_loss: 16913.1175 - val_acc: 0.7253\n",
      "Epoch 352/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 10511.3678 - acc: 0.8027 - val_loss: 18163.5492 - val_acc: 0.7040\n",
      "Epoch 353/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 36619.7619 - acc: 0.6013 - val_loss: 26135.9370 - val_acc: 0.6427\n",
      "Epoch 354/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 28615.5867 - acc: 0.6360 - val_loss: 32174.2749 - val_acc: 0.6027\n",
      "Epoch 355/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 35958.7252 - acc: 0.6000 - val_loss: 21856.9756 - val_acc: 0.6787\n",
      "Epoch 356/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 25840.6356 - acc: 0.6360 - val_loss: 29149.6891 - val_acc: 0.6280\n",
      "Epoch 357/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 33987.9280 - acc: 0.6000 - val_loss: 26335.2415 - val_acc: 0.6493\n",
      "Epoch 358/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 23859.7085 - acc: 0.6693 - val_loss: 14757.2564 - val_acc: 0.7467\n",
      "Epoch 359/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 23118.6799 - acc: 0.6653 - val_loss: 16219.4577 - val_acc: 0.7253\n",
      "Epoch 360/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 8304.6638 - acc: 0.8093 - val_loss: 15691.7272 - val_acc: 0.7240\n",
      "Epoch 361/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 17751.2545 - acc: 0.7160 - val_loss: 21202.4288 - val_acc: 0.6800\n",
      "Epoch 362/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 30849.6251 - acc: 0.6333 - val_loss: 35153.1103 - val_acc: 0.5933\n",
      "Epoch 363/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 39223.6256 - acc: 0.5653 - val_loss: 50202.7149 - val_acc: 0.5520\n",
      "Epoch 364/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 36003.6086 - acc: 0.5947 - val_loss: 60470.7586 - val_acc: 0.5267\n",
      "Epoch 365/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 28921.6514 - acc: 0.6560 - val_loss: 25835.0946 - val_acc: 0.6547\n",
      "Epoch 366/500\n",
      "750/750 [==============================] - 0s 58us/sample - loss: 21642.1211 - acc: 0.6960 - val_loss: 18095.2394 - val_acc: 0.7053\n",
      "Epoch 367/500\n",
      "750/750 [==============================] - 0s 65us/sample - loss: 16086.8960 - acc: 0.7387 - val_loss: 8869.2400 - val_acc: 0.8053\n",
      "Epoch 368/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 6901.9972 - acc: 0.8427 - val_loss: 8148.3191 - val_acc: 0.8240\n",
      "Epoch 369/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 14474.8723 - acc: 0.7480 - val_loss: 18834.1725 - val_acc: 0.7160\n",
      "Epoch 370/500\n",
      "750/750 [==============================] - 0s 55us/sample - loss: 14060.7174 - acc: 0.7453 - val_loss: 29232.6815 - val_acc: 0.6347\n",
      "Epoch 371/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 26361.5021 - acc: 0.6627 - val_loss: 33953.6221 - val_acc: 0.6000\n",
      "Epoch 372/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 32710.6961 - acc: 0.6173 - val_loss: 40033.0506 - val_acc: 0.5733\n",
      "Epoch 373/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 37161.8028 - acc: 0.5733 - val_loss: 38715.0206 - val_acc: 0.5800\n",
      "Epoch 374/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 29785.8087 - acc: 0.6253 - val_loss: 46366.5439 - val_acc: 0.5533\n",
      "Epoch 375/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 26482.5725 - acc: 0.6560 - val_loss: 26236.4661 - val_acc: 0.6533\n",
      "Epoch 376/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 24817.7665 - acc: 0.6653 - val_loss: 11893.5041 - val_acc: 0.7800\n",
      "Epoch 377/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 6644.7648 - acc: 0.8387 - val_loss: 6151.4636 - val_acc: 0.8533\n",
      "Epoch 378/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 6921.3824 - acc: 0.8373 - val_loss: 18869.8261 - val_acc: 0.7147\n",
      "Epoch 379/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 26492.5889 - acc: 0.6547 - val_loss: 32459.6090 - val_acc: 0.6173\n",
      "Epoch 380/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 21818.1284 - acc: 0.6987 - val_loss: 26098.2427 - val_acc: 0.6587\n",
      "Epoch 381/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 28235.6200 - acc: 0.6493 - val_loss: 19880.3658 - val_acc: 0.7080\n",
      "Epoch 382/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 14112.7629 - acc: 0.7600 - val_loss: 26536.5423 - val_acc: 0.6520\n",
      "Epoch 383/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 23629.3651 - acc: 0.6787 - val_loss: 11337.7320 - val_acc: 0.7867\n",
      "Epoch 384/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 13025.3453 - acc: 0.7533 - val_loss: 21502.9866 - val_acc: 0.6907\n",
      "Epoch 385/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 8961.4658 - acc: 0.8360 - val_loss: 5214.1479 - val_acc: 0.8600\n",
      "Epoch 386/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 7259.0130 - acc: 0.8360 - val_loss: 12350.8612 - val_acc: 0.7493\n",
      "Epoch 387/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 5498.1649 - acc: 0.8480 - val_loss: 12367.4047 - val_acc: 0.7733\n",
      "Epoch 388/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 22878.8872 - acc: 0.6853 - val_loss: 10459.5644 - val_acc: 0.7893\n",
      "Epoch 389/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 16521.1880 - acc: 0.7227 - val_loss: 24400.4291 - val_acc: 0.6613\n",
      "Epoch 390/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 30783.2425 - acc: 0.6000 - val_loss: 71557.2094 - val_acc: 0.5267\n",
      "Epoch 391/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 22415.6886 - acc: 0.7160 - val_loss: 19263.5296 - val_acc: 0.7147\n",
      "Epoch 392/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 19915.4058 - acc: 0.7013 - val_loss: 51845.5431 - val_acc: 0.5360\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 49us/sample - loss: 41210.5884 - acc: 0.5520 - val_loss: 43929.8372 - val_acc: 0.5573\n",
      "Epoch 394/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 25575.1969 - acc: 0.6600 - val_loss: 40913.4684 - val_acc: 0.5720\n",
      "Epoch 395/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 18883.0605 - acc: 0.7107 - val_loss: 16942.3256 - val_acc: 0.7227\n",
      "Epoch 396/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 17198.3383 - acc: 0.7240 - val_loss: 20207.5029 - val_acc: 0.7067\n",
      "Epoch 397/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 28103.6218 - acc: 0.6347 - val_loss: 21833.3911 - val_acc: 0.6880\n",
      "Epoch 398/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 37070.3469 - acc: 0.5787 - val_loss: 18629.5936 - val_acc: 0.7173\n",
      "Epoch 399/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 9076.0835 - acc: 0.8307 - val_loss: 18127.9593 - val_acc: 0.7213\n",
      "Epoch 400/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 29385.2271 - acc: 0.6467 - val_loss: 32604.0687 - val_acc: 0.6080\n",
      "Epoch 401/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 32643.6012 - acc: 0.6173 - val_loss: 41677.9986 - val_acc: 0.5680\n",
      "Epoch 402/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 14591.5254 - acc: 0.7587 - val_loss: 26415.2165 - val_acc: 0.6507\n",
      "Epoch 403/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 29432.5482 - acc: 0.6333 - val_loss: 14460.8953 - val_acc: 0.7493\n",
      "Epoch 404/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 27481.3676 - acc: 0.6267 - val_loss: 40084.2947 - val_acc: 0.5693\n",
      "Epoch 405/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 42714.9567 - acc: 0.5493 - val_loss: 39140.7121 - val_acc: 0.5760\n",
      "Epoch 406/500\n",
      "750/750 [==============================] - 0s 55us/sample - loss: 29188.1344 - acc: 0.6400 - val_loss: 20410.8633 - val_acc: 0.6893\n",
      "Epoch 407/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 29228.7381 - acc: 0.6307 - val_loss: 33205.8771 - val_acc: 0.6027\n",
      "Epoch 408/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 24085.1737 - acc: 0.6600 - val_loss: 14346.7150 - val_acc: 0.7480\n",
      "Epoch 409/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 17232.7061 - acc: 0.7200 - val_loss: 19739.9869 - val_acc: 0.7067\n",
      "Epoch 410/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 16911.4931 - acc: 0.7187 - val_loss: 33559.4736 - val_acc: 0.6013\n",
      "Epoch 411/500\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 31516.0387 - acc: 0.6240 - val_loss: 19316.2641 - val_acc: 0.7120\n",
      "Epoch 412/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 20339.4819 - acc: 0.6960 - val_loss: 13713.4723 - val_acc: 0.7640\n",
      "Epoch 413/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 23614.1748 - acc: 0.6933 - val_loss: 24754.4833 - val_acc: 0.6627\n",
      "Epoch 414/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 19785.6046 - acc: 0.7213 - val_loss: 5565.8501 - val_acc: 0.8613\n",
      "Epoch 415/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 8336.7747 - acc: 0.8240 - val_loss: 4974.3408 - val_acc: 0.8640\n",
      "Epoch 416/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 6784.1038 - acc: 0.8293 - val_loss: 8192.6930 - val_acc: 0.8227\n",
      "Epoch 417/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 9383.2391 - acc: 0.8160 - val_loss: 8009.5680 - val_acc: 0.8227\n",
      "Epoch 418/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 14649.0270 - acc: 0.7573 - val_loss: 34441.4133 - val_acc: 0.5907\n",
      "Epoch 419/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 29777.5822 - acc: 0.6240 - val_loss: 33824.1862 - val_acc: 0.5933\n",
      "Epoch 420/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 25032.6718 - acc: 0.6720 - val_loss: 12660.3759 - val_acc: 0.7693\n",
      "Epoch 421/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 20719.6803 - acc: 0.6893 - val_loss: 69381.5605 - val_acc: 0.5267\n",
      "Epoch 422/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 13072.3383 - acc: 0.8360 - val_loss: 4679.3392 - val_acc: 0.8680\n",
      "Epoch 423/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 6832.3584 - acc: 0.8333 - val_loss: 7568.0256 - val_acc: 0.8240\n",
      "Epoch 424/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 15359.8849 - acc: 0.7267 - val_loss: 32783.1148 - val_acc: 0.5987\n",
      "Epoch 425/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 36116.6674 - acc: 0.5853 - val_loss: 23334.2227 - val_acc: 0.6733\n",
      "Epoch 426/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 23666.4117 - acc: 0.6653 - val_loss: 26067.2583 - val_acc: 0.6547\n",
      "Epoch 427/500\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 19053.3992 - acc: 0.7107 - val_loss: 5887.0981 - val_acc: 0.8587\n",
      "Epoch 428/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 5389.5926 - acc: 0.8480 - val_loss: 4533.4777 - val_acc: 0.8733\n",
      "Epoch 429/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 4921.0099 - acc: 0.8560 - val_loss: 7159.9813 - val_acc: 0.8293\n",
      "Epoch 430/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 4894.6235 - acc: 0.8613 - val_loss: 4602.5605 - val_acc: 0.8733\n",
      "Epoch 431/500\n",
      "750/750 [==============================] - 0s 60us/sample - loss: 7009.1205 - acc: 0.8320 - val_loss: 7998.9968 - val_acc: 0.8213\n",
      "Epoch 432/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 16460.7598 - acc: 0.7240 - val_loss: 39490.8061 - val_acc: 0.5720\n",
      "Epoch 433/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 46927.0224 - acc: 0.5200 - val_loss: 22987.6214 - val_acc: 0.6720\n",
      "Epoch 434/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 25491.3154 - acc: 0.6867 - val_loss: 10721.4130 - val_acc: 0.7853\n",
      "Epoch 435/500\n",
      "750/750 [==============================] - 0s 56us/sample - loss: 9126.5441 - acc: 0.7947 - val_loss: 6875.5111 - val_acc: 0.8320\n",
      "Epoch 436/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 17964.8014 - acc: 0.7133 - val_loss: 18107.9339 - val_acc: 0.7133\n",
      "Epoch 437/500\n",
      "750/750 [==============================] - 0s 51us/sample - loss: 21362.4319 - acc: 0.7013 - val_loss: 13430.9373 - val_acc: 0.7560\n",
      "Epoch 438/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 27735.2955 - acc: 0.6320 - val_loss: 36489.4414 - val_acc: 0.5827\n",
      "Epoch 439/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 38421.9716 - acc: 0.5840 - val_loss: 13178.7761 - val_acc: 0.7560\n",
      "Epoch 440/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 16946.0152 - acc: 0.7307 - val_loss: 25106.5758 - val_acc: 0.6507\n",
      "Epoch 441/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 34034.9364 - acc: 0.5960 - val_loss: 46903.4900 - val_acc: 0.5507\n",
      "Epoch 442/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 23893.7773 - acc: 0.6827 - val_loss: 13745.7847 - val_acc: 0.7520\n",
      "Epoch 443/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 22731.1915 - acc: 0.6600 - val_loss: 19781.4164 - val_acc: 0.7053\n",
      "Epoch 444/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 12745.4720 - acc: 0.7640 - val_loss: 10041.2338 - val_acc: 0.8000\n",
      "Epoch 445/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 7561.3658 - acc: 0.8333 - val_loss: 5777.4802 - val_acc: 0.8573\n",
      "Epoch 446/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 5279.8516 - acc: 0.8653 - val_loss: 4422.1125 - val_acc: 0.8760\n",
      "Epoch 447/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 4687.1870 - acc: 0.8773 - val_loss: 4253.5785 - val_acc: 0.8773\n",
      "Epoch 448/500\n",
      "750/750 [==============================] - 0s 61us/sample - loss: 4913.4102 - acc: 0.8627 - val_loss: 8268.0214 - val_acc: 0.8120\n",
      "Epoch 449/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 7352.9227 - acc: 0.8387 - val_loss: 20757.4141 - val_acc: 0.6933\n",
      "Epoch 450/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 16941.3332 - acc: 0.7347 - val_loss: 13507.1043 - val_acc: 0.7613\n",
      "Epoch 451/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 13861.3324 - acc: 0.7453 - val_loss: 24306.4119 - val_acc: 0.6533\n",
      "Epoch 452/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 37199.1582 - acc: 0.5747 - val_loss: 28573.9448 - val_acc: 0.6267\n",
      "Epoch 453/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 38742.8773 - acc: 0.5693 - val_loss: 43452.0601 - val_acc: 0.5587\n",
      "Epoch 454/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 20897.8866 - acc: 0.7013 - val_loss: 14293.1211 - val_acc: 0.7547\n",
      "Epoch 455/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 8171.8458 - acc: 0.8387 - val_loss: 4234.1250 - val_acc: 0.8800\n",
      "Epoch 456/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 6505.2664 - acc: 0.8333 - val_loss: 10188.0314 - val_acc: 0.7760\n",
      "Epoch 457/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 5641.5382 - acc: 0.8467 - val_loss: 5363.4318 - val_acc: 0.8467\n",
      "Epoch 458/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 4137.2928 - acc: 0.8867 - val_loss: 4639.2179 - val_acc: 0.8547\n",
      "Epoch 459/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 14193.0070 - acc: 0.7560 - val_loss: 29640.5480 - val_acc: 0.6093\n",
      "Epoch 460/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 32526.4974 - acc: 0.6093 - val_loss: 15850.1493 - val_acc: 0.7053\n",
      "Epoch 461/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 28968.1690 - acc: 0.6253 - val_loss: 7062.4342 - val_acc: 0.8280\n",
      "Epoch 462/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 6346.9074 - acc: 0.8387 - val_loss: 4759.8411 - val_acc: 0.8640\n",
      "Epoch 463/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 17280.4839 - acc: 0.7267 - val_loss: 43831.7264 - val_acc: 0.5560\n",
      "Epoch 464/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 32041.3791 - acc: 0.6000 - val_loss: 31949.5949 - val_acc: 0.5933\n",
      "Epoch 465/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 20827.4191 - acc: 0.6933 - val_loss: 24292.0382 - val_acc: 0.6427\n",
      "Epoch 466/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 24910.6703 - acc: 0.6453 - val_loss: 25428.4494 - val_acc: 0.6373\n",
      "Epoch 467/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 36495.6970 - acc: 0.5653 - val_loss: 36216.5939 - val_acc: 0.5773\n",
      "Epoch 468/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 31501.6161 - acc: 0.6173 - val_loss: 13697.0956 - val_acc: 0.7453\n",
      "Epoch 469/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 14606.2570 - acc: 0.7480 - val_loss: 22195.2770 - val_acc: 0.6627\n",
      "Epoch 470/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 27527.1711 - acc: 0.6200 - val_loss: 41589.0112 - val_acc: 0.5640\n",
      "Epoch 471/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 28717.4056 - acc: 0.6227 - val_loss: 14199.4350 - val_acc: 0.7400\n",
      "Epoch 472/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 15261.0538 - acc: 0.7333 - val_loss: 11980.4672 - val_acc: 0.7653\n",
      "Epoch 473/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 9954.1060 - acc: 0.8040 - val_loss: 4069.2463 - val_acc: 0.8827\n",
      "Epoch 474/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 4107.1955 - acc: 0.8813 - val_loss: 4322.9181 - val_acc: 0.8733\n",
      "Epoch 475/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 3987.9918 - acc: 0.8787 - val_loss: 3895.1945 - val_acc: 0.8840\n",
      "Epoch 476/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 4404.7160 - acc: 0.8693 - val_loss: 4752.8389 - val_acc: 0.8587\n",
      "Epoch 477/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 9216.4339 - acc: 0.7920 - val_loss: 7832.6695 - val_acc: 0.8147\n",
      "Epoch 478/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 8041.2423 - acc: 0.8107 - val_loss: 4734.9121 - val_acc: 0.8573\n",
      "Epoch 479/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 5166.8902 - acc: 0.8667 - val_loss: 9400.2239 - val_acc: 0.7853\n",
      "Epoch 480/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 21378.7365 - acc: 0.6627 - val_loss: 51236.8069 - val_acc: 0.5360\n",
      "Epoch 481/500\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 41384.9874 - acc: 0.5520 - val_loss: 27525.4477 - val_acc: 0.6293\n",
      "Epoch 482/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 30195.0614 - acc: 0.6200 - val_loss: 32271.8751 - val_acc: 0.5960\n",
      "Epoch 483/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 26178.5578 - acc: 0.6520 - val_loss: 20860.1022 - val_acc: 0.6733\n",
      "Epoch 484/500\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 21866.7992 - acc: 0.7160 - val_loss: 4182.3763 - val_acc: 0.8760\n",
      "Epoch 485/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 4218.8791 - acc: 0.8787 - val_loss: 3856.5096 - val_acc: 0.8880\n",
      "Epoch 486/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 3864.9936 - acc: 0.8787 - val_loss: 4219.7156 - val_acc: 0.8760\n",
      "Epoch 487/500\n",
      "750/750 [==============================] - 0s 48us/sample - loss: 3990.4484 - acc: 0.8773 - val_loss: 8483.3136 - val_acc: 0.8080\n",
      "Epoch 488/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 15327.8348 - acc: 0.7400 - val_loss: 16250.7850 - val_acc: 0.7347\n",
      "Epoch 489/500\n",
      "750/750 [==============================] - 0s 42us/sample - loss: 29548.2539 - acc: 0.6160 - val_loss: 14995.9376 - val_acc: 0.7493\n",
      "Epoch 490/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 15194.5176 - acc: 0.7507 - val_loss: 26499.9931 - val_acc: 0.6293\n",
      "Epoch 491/500\n",
      "750/750 [==============================] - 0s 47us/sample - loss: 17883.1061 - acc: 0.7080 - val_loss: 6025.7463 - val_acc: 0.8387\n",
      "Epoch 492/500\n",
      "750/750 [==============================] - 0s 44us/sample - loss: 3929.1273 - acc: 0.8747 - val_loss: 4201.9515 - val_acc: 0.8640\n",
      "Epoch 493/500\n",
      "750/750 [==============================] - 0s 50us/sample - loss: 5203.0544 - acc: 0.8480 - val_loss: 9507.8068 - val_acc: 0.7853\n",
      "Epoch 494/500\n",
      "750/750 [==============================] - 0s 45us/sample - loss: 21079.3884 - acc: 0.6560 - val_loss: 35952.5183 - val_acc: 0.5800\n",
      "Epoch 495/500\n",
      "750/750 [==============================] - 0s 52us/sample - loss: 32440.4449 - acc: 0.6187 - val_loss: 14299.6271 - val_acc: 0.7293\n",
      "Epoch 496/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 11263.0781 - acc: 0.7907 - val_loss: 3748.6789 - val_acc: 0.8800\n",
      "Epoch 497/500\n",
      "750/750 [==============================] - 0s 54us/sample - loss: 5417.4902 - acc: 0.8653 - val_loss: 9153.4864 - val_acc: 0.7960\n",
      "Epoch 498/500\n",
      "750/750 [==============================] - 0s 38us/sample - loss: 14665.2397 - acc: 0.7280 - val_loss: 12757.1244 - val_acc: 0.7493\n",
      "Epoch 499/500\n",
      "750/750 [==============================] - 0s 49us/sample - loss: 17093.3971 - acc: 0.7120 - val_loss: 13699.1647 - val_acc: 0.7387\n",
      "Epoch 500/500\n",
      "750/750 [==============================] - 0s 46us/sample - loss: 27755.7281 - acc: 0.6400 - val_loss: 14410.6451 - val_acc: 0.7320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bc05dcf60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from preprocessing import processor\n",
    "import dataset.dataloader as data_loader\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from time import time\n",
    "\n",
    "path = \"/home/ktranrb/Desktop/image_classifier/dataset/train\"\n",
    "\n",
    "le = preprocessing.LabelBinarizer()\n",
    "\n",
    "p = processor.Processor(28, 28)\n",
    "\n",
    "loader = data_loader.DataLoader(preprocessor=p)\n",
    "data, label = loader.load(path, size=1000)\n",
    "\n",
    "le.fit(label)\n",
    "labels = le.transform(label)\n",
    "labels = np.where(labels==[0], [1,0], [0,1])\n",
    "print(labels)\n",
    "\n",
    "data = data.reshape(data.shape[0], 28*28*3)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "                                                  test_size=0.25)\n",
    "\n",
    "sgd = SGD(nesterov=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(trainX, trainY, validation_data=(trainX, trainY),\n",
    "              batch_size=128, epochs=500, verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6007\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8b62821cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
